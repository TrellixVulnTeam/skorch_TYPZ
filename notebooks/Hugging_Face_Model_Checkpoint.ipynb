{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating checkpoints on the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short notebook explains how you can create a model checkpoint on [Hugging Face Hub](https://huggingface.co/docs/hub/repositories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import TrainEndCheckpoint\n",
    "from skorch.hf import HfHubWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository, create_repo, HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not installed already, please install the [Hugging Face Hub](https://huggingface.co/docs/huggingface_hub/index) library:\n",
    "\n",
    "`$ python -m pip install huggingface_hub`\n",
    "\n",
    "Also, you need `skorch>=0.12` or installed from the master branch on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/Hugging_Face_Checkpoint.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/Hugging_Face_Checkpoint.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ ! -z \"$COLAB_GPU\" ] && pip install torch \"skorch>=0.12\" huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the token as an environment variable called HF_TOKEN, e.g. `HF_TOKEN=hf_...`\n",
    "# the token can be found at: https://huggingface.co/settings/tokens\n",
    "TOKEN = os.environ['HF_TOKEN']\n",
    "# choose name for the whole model and for the model weights\n",
    "# typically, you only need one of the two, we use both for demonstration purposes\n",
    "MODEL_NAME = 'skorch-model.pkl'\n",
    "WEIGHTS_NAME = 'weights.pt'\n",
    "# choose a repo name within your user account or organization\n",
    "REPO_NAME = 'BenjaminB/test-skorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a toy dataset for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(10000, 20, n_informative=10, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=nn.ReLU(),\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.softmax(self.output(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a repository on Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the repo doesn't exist yet, create a new one using this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skorch_repo = create_repo(\n",
    "    REPO_NAME,\n",
    "    private=True,  # set to False if it should be public\n",
    "    token=TOKEN,\n",
    "    exist_ok=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BenjaminB/test-skorch'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `HfHubWriter` instance to use with the `TrainEndCheckpoint` callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ingredient we need to save models on the hub is the `skorch.hf.HfHubWriter`. This writer can be used instead of a filename when you use `skorch.callbacks.TrainEndCheckpoint` (or `skorch.callbacks.Checkpoint`, but more on that later). Therefore, you can continue to use your existing checkpoints, only that models are stored on Hugging Face Hub instead of locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we need to create a `HfApi` instance, which is used by the `HfHubWriter` to perform the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api = HfApi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create a `hub_pickle_writer`, which is used by the checkpoint callback to write the whole skorch model as a pickle file to the indicated repository. We indicate the file path, repository name, and the Hugging Face token. Optionally, we can also set `verbose=1` to print a message when a file has been uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_pickle_writer = HfHubWriter(\n",
    "    hf_api,\n",
    "    path_in_repo=MODEL_NAME,\n",
    "    repo_id=REPO_NAME,\n",
    "    token=TOKEN,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing the whole skorch model to the Hub, we can also decide to only write specific components, e.g. the `module`. This saves the `state_dict` of the module to the Hub using `torch.save` under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_params_writer = HfHubWriter(\n",
    "    hf_api,\n",
    "    path_in_repo=WEIGHTS_NAME,\n",
    "    repo_id=REPO_NAME,\n",
    "    token=TOKEN,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other attributes (optimizer, criterion, training history) are not saved for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = TrainEndCheckpoint(\n",
    "    f_pickle=hub_pickle_writer,\n",
    "    f_params=hub_params_writer,\n",
    "    f_optimizer=None,\n",
    "    f_criterion=None,\n",
    "    f_history=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    device='cpu',\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6513\u001b[0m       \u001b[32m0.7887\u001b[0m        \u001b[35m0.5560\u001b[0m  0.1043\n",
      "      2        \u001b[36m0.5736\u001b[0m       \u001b[32m0.8527\u001b[0m        \u001b[35m0.4521\u001b[0m  0.0820\n",
      "      3        \u001b[36m0.5219\u001b[0m       \u001b[32m0.8633\u001b[0m        \u001b[35m0.4045\u001b[0m  0.0806\n",
      "      4        \u001b[36m0.4940\u001b[0m       \u001b[32m0.8820\u001b[0m        \u001b[35m0.3720\u001b[0m  0.0853\n",
      "      5        \u001b[36m0.4728\u001b[0m       0.8787        \u001b[35m0.3509\u001b[0m  0.0808\n",
      "      6        \u001b[36m0.4558\u001b[0m       \u001b[32m0.8867\u001b[0m        \u001b[35m0.3443\u001b[0m  0.1058\n",
      "      7        \u001b[36m0.4378\u001b[0m       \u001b[32m0.8907\u001b[0m        \u001b[35m0.3293\u001b[0m  0.1181\n",
      "      8        \u001b[36m0.4335\u001b[0m       \u001b[32m0.8993\u001b[0m        \u001b[35m0.3242\u001b[0m  0.1283\n",
      "      9        \u001b[36m0.4289\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.3084\u001b[0m  0.1084\n",
      "     10        \u001b[36m0.4070\u001b[0m       \u001b[32m0.9067\u001b[0m        \u001b[35m0.3053\u001b[0m  0.1229\n",
      "     11        0.4092       \u001b[32m0.9140\u001b[0m        \u001b[35m0.2953\u001b[0m  0.1109\n",
      "     12        0.4103       \u001b[32m0.9160\u001b[0m        0.3011  0.1060\n",
      "     13        \u001b[36m0.3889\u001b[0m       0.9113        \u001b[35m0.2896\u001b[0m  0.1065\n",
      "     14        0.3952       0.9067        0.2954  0.0923\n",
      "     15        \u001b[36m0.3889\u001b[0m       0.9073        0.2990  0.1029\n",
      "     16        0.3902       0.9033        0.2979  0.0862\n",
      "     17        \u001b[36m0.3811\u001b[0m       0.9087        0.2923  0.0820\n",
      "     18        \u001b[36m0.3800\u001b[0m       0.9053        \u001b[35m0.2872\u001b[0m  0.0801\n",
      "     19        \u001b[36m0.3782\u001b[0m       \u001b[32m0.9187\u001b[0m        0.2883  0.0825\n",
      "     20        0.3835       0.8993        0.3077  0.0823\n",
      "Uploaded file to https://huggingface.co/BenjaminB/test-skorch/blob/main/weights.pt\n",
      "Uploaded file to https://huggingface.co/BenjaminB/test-skorch/blob/main/skorch-model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (nonlin): ReLU()\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, both the weights of the PyTorch module and the whole skorch model were saved on Hub. Visit the printed URLs to see them on the Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, think about adding a [Model Card](https://huggingface.co/docs/hub/models-cards) to your repository to provide further information about the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Info: Using the HfHubWriter with Checkpoint:</b><br>\n",
    "\n",
    "\n",
    "Right now, we use `TrainEndCheckpoint`, which uploads the model only once, at the end of training. Instead, we could use `Checkpoint`, which uploads the model each time that the monitored metric improves. You should note, however, that at the moment, the upload is _synchronous_, i.e. we wait for the upload to finish. So if uploading the model takes a long time compared to training the model, your training process could be slowed down considerably, depending on how often the model improves.\n",
    "\n",
    "If you still decide to use `Checkpoint`, you might want to keep a version of each upload file, instead of the latest one overwriting the previous one. This is possible by choosing a templated model name, e.g. `'skorch-model-{}.pkl'`. This way, the first upload will create the file `'skorch-model-0.pkl'`, the second one creates the file `'skorch-model-1.pkl'`, etc.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skorch model is just a normal pickle file and can be loaded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BenjaminB/test-skorch/blob/main/skorch-model.pkl'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_pickle_writer.latest_url_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869292a71e324577af285433f70b2fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/68.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = hf_hub_download(REPO_NAME, MODEL_NAME, use_auth_token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    net_loaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, net_loaded.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model weights are stored as a PyTorch `state_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/BenjaminB/test-skorch/blob/main/weights.pt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_params_writer.latest_url_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = hf_hub_download(REPO_NAME, WEIGHTS_NAME, use_auth_token=TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'rb') as f:\n",
    "    weights_loaded = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name 'dense0.weight' and shape torch.Size([10, 20])\n",
      "Parameter name 'dense0.bias' and shape torch.Size([10])\n",
      "Parameter name 'dense1.weight' and shape torch.Size([10, 10])\n",
      "Parameter name 'dense1.bias' and shape torch.Size([10])\n",
      "Parameter name 'output.weight' and shape torch.Size([2, 10])\n",
      "Parameter name 'output.bias' and shape torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for key, val in weights_loaded.items():\n",
    "    print(f\"Parameter name '{key}' and shape {val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, when you store the whole skorch model, you don't need to store the weights separately, as they are already part of the whole model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name 'dense0.weight' and shape torch.Size([10, 20])\n",
      "Parameter name 'dense0.bias' and shape torch.Size([10])\n",
      "Parameter name 'dense1.weight' and shape torch.Size([10, 10])\n",
      "Parameter name 'dense1.bias' and shape torch.Size([10])\n",
      "Parameter name 'output.weight' and shape torch.Size([2, 10])\n",
      "Parameter name 'output.bias' and shape torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for key, val in net_loaded.module_.state_dict().items():\n",
    "    print(f\"Parameter name '{key}' and shape {val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there can be situations where you don't need the whole skorch model, in which case you can only store the model weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
